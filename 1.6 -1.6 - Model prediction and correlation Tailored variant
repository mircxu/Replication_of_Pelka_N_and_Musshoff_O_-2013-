# Clear the workspace
rm(list = ls())

# Load required packages
library(dplyr)
library(broom)
library(lme4)
library(lmerTest)
library(purrr)
library(tidyr)
library(stringr)

# Load  data (adjust the path as necessary)
df_raw <- read.csv('final_merged_data.csv')



# Verify the type and structure of df
if (!is.data.frame(df_raw)) {
  stop("The object 'df' is not a data frame. Please check your data loading process.")
}

# Inspect the first few rows and structure
print(head(df))
str(df)

# Print column names to verify
print(names(df))

# Rename columns if necessary (update the names to match your data)
df <- df_raw %>%
  rename(
    IR_t = `IR`,        # Update to actual column names if different
    IT_t = `IT`,        # Update to actual column names if different
    Y_t = `Yield`,      # Update to actual column names if different
    Farm = `stations_id`, # Update to actual column names if different
    Year = `year` ,      # Update to actual column names if different
    accumulation_period = Correlation
  )


# check column names after renaming
print(names(df))

# Proceed only if all required columns are present
required_columns <- c("IR_t", "IT_t", "Y_t", "Farm", "Year")
missing_columns <- setdiff(required_columns, names(df))
if (length(missing_columns) > 0) {
  stop(paste("The following required columns are missing:", paste(missing_columns, collapse = ", ")))
}

# Remove rows with NA values in  columns
df <- df %>%
  filter(!is.na(IR_t) & !is.na(IT_t) & !is.na(Y_t))


# Recreate additional columns
df <- df %>%
  mutate(IR_t_squared = IR_t^2,
         IT_t_squared = IT_t^2,
         IR_t_IT_t = IR_t * IT_t)

# Check for any remaining NA values in the new columns
na_check <- df %>%
  summarise(across(c(IR_t, IT_t, IR_t_squared, IT_t_squared, IR_t_IT_t, Y_t), ~ sum(is.na(.))))
print(na_check)

# Print group sizes
group_sizes <- df %>%
  group_by(Farm) %>%
  summarise(count = n())
print(group_sizes)

# Debug data for each group
df %>%
  group_by(district_no, accumulation_period) %>%
  do({
    cat("Group:", unique(.$Farm), "\n")
    print(head(.))
    .
  })

# Separate Models for Each Farm
models_farms <- df %>%
  group_by(district_no, accumulation_period) %>%
  do({
    data <- .
    if (nrow(data) > 0) { # Ensure there is data to model
      model <- lm(Y_t ~ IR_t + IT_t + IR_t_squared + IT_t_squared + IR_t_IT_t, data = data)
      tidy(model) %>%
        mutate(district_no = unique(data$district_no)) # Add Farm identifier to each result
    } else {
      tibble() # Return an empty tibble if no data
    }
  })

# Print summaries of models for each farm
print(models_farms)

#write the coefficients to a CSV file
write.csv(models_farms, 'models_farms_coefficients.csv', row.names = FALSE)


df %>% 
  left_join(models_farms, by=c("district_no", "accumulation_period"))






models_farms_wider <- models_farms %>% 
  #filter(district_no == 1003 & accumulation_period == '3:8') %>% 
  select(c(1, 2, 3, 7)) %>% 
  mutate(term = str_replace_all(term, "[()]", ""),
         term = paste0(term, '_coef')) %>% 
  pivot_wider(id_cols = c('accumulation_period','district_no'),
              names_from = 'term', values_from = 'estimate')

df_with_coef <- df %>% 
  #  filter(district_no==1003 & accumulation_period=='3:8') %>% 
  tibble() %>%
  inner_join(models_farms_wider, by=c("district_no", "accumulation_period"))


df_with_coef %>% glimpse()


library(dplyr)

df_with_coef <- df_with_coef %>%
  mutate(prediction = Intercept_coef +
           IR_t_coef * IR_t +
           IT_t_coef * IT_t +
           IR_t_squared_coef * IR_t_squared +
           IT_t_squared_coef * IT_t_squared +
           IR_t_IT_t_coef * IR_t_IT_t)



df_lbl <- df_with_coef %>% 
  group_split(district_no, accumulation_period) %>% 
  map_dfr(~ .x %>% select(district_no, accumulation_period) %>% distinct())

df_corr <-df_with_coef %>% 
  group_split(district_no, accumulation_period) %>% 
  map_dfr( ~ .x %>% select(Y_t, prediction) %>% cor() %>% data.frame() %>% 
             select(prediction) %>% slice(1) %>% rename(coef_=prediction))

df_lbl$corrcoef_ <- df_corr$coef_
df_corr <- df_lbl

df_corr$corrcoef_ %>% min() # No negative coefficient

best_corr_per_district <- df_corr %>%
  group_split(district_no) %>%
  map(~ .x %>% arrange(desc(corrcoef_)) %>% slice(1)) %>%
  bind_rows()

# Display the best correlations
print(best_corr_per_district)

# Save the best correlations to a CSV file
write.csv(best_corr_per_district, 'best_corr_per_district.csv', row.names = FALSE)
