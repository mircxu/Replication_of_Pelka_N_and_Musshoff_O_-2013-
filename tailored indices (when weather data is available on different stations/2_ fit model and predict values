# Clear the workspace
rm(list = ls())

# Load required packages
library(dplyr)
library(broom)
library(lme4)
library(lmerTest)
library(purrr)
library(tidyr)
library(stringr)

# Load data (use the new file path)
df_raw <- read.csv('Final_merged_data_different_stations.csv')

# Verify the type and structure of df_raw
if (!is.data.frame(df_raw)) {
  stop("The object 'df_raw' is not a data frame. Please check your data loading process.")
}

# Inspect the first few rows and structure
print(head(df_raw))
str(df_raw)

# Print column names to verify
print(names(df_raw))

# Rename columns to match your data
df <- df_raw %>%
  rename(
    IR_t = `IR`,                    # Update to the correct column name if necessary
    IT_t = `IT`,                    # Update to the correct column name if necessary
    Y_t = `Yield`,                  # Update to the correct column name if necessary
    stations_rain = `Station_Rain`, # Correctly reference the rain station ID
    stations_temp = `Station_Temp`, # Correctly reference the temperature station ID
    Year = `year`,                  # Update to the correct column name if necessary
    accumulation_period = `Correlation`
  )

# Check column names after renaming
print(names(df))

# Proceed only if all required columns are present
required_columns <- c("IR_t", "IT_t", "Y_t", "stations_rain", "stations_temp", "Year")
missing_columns <- setdiff(required_columns, names(df))
if (length(missing_columns) > 0) {
  stop(paste("The following required columns are missing:", paste(missing_columns, collapse = ", ")))
}

# Remove rows with NA values in columns
df <- df %>%
  filter(!is.na(IR_t) & !is.na(IT_t) & !is.na(Y_t))

# Recreate additional columns
df <- df %>%
  mutate(IR_t_squared = IR_t^2,
         IT_t_squared = IT_t^2,
         IR_t_IT_t = IR_t * IT_t)

# Check for any remaining NA values in the new columns
na_check <- df %>%
  summarise(across(c(IR_t, IT_t, IR_t_squared, IT_t_squared, IR_t_IT_t, Y_t), ~ sum(is.na(.))))
print(na_check)

# Print group sizes
group_sizes <- df %>%
  group_by(stations_rain) %>%
  summarise(count = n())
print(group_sizes)

# Debug data for each group
df %>%
  group_by(district_no, accumulation_period) %>%
  do({
    cat("Group:", unique(.$stations_rain), "\n")
    print(head(.))
    .
  })

# Separate Models for Each district
models_stations <- df %>%
  group_by(district_no, accumulation_period) %>%
  do({
    data <- .
    if (nrow(data) > 0) { # Ensure there is data to model
      model <- lm(Y_t ~ IR_t + IT_t + IR_t_squared + IT_t_squared + IR_t_IT_t, data = data)
      tidy(model) %>%
        mutate(district_no = unique(data$district_no)) # Add district identifier to each result
    } else {
      tibble() # Return an empty tibble if no data
    }
  })

# Print summaries of models for each district
print(models_stations)

# Write the coefficients to a CSV file
write.csv(models_stations, 'models_stations_coefficients_diff.csv', row.names = FALSE)

# Preparing data for predictions
models_stations_wider <- models_stations %>% 
  select(c(1, 2, 3, 7)) %>% 
  mutate(term = str_replace_all(term, "[()]", ""),
         term = paste0(term, '_coef')) %>% 
  pivot_wider(id_cols = c('accumulation_period','district_no'),
              names_from = 'term', values_from = 'estimate')

df_with_coef <- df %>% 
  tibble() %>%
  inner_join(models_stations_wider, by=c("district_no", "accumulation_period"))

df_with_coef %>% glimpse()

df_with_coef <- df_with_coef %>%
  mutate(prediction = Intercept_coef +
           IR_t_coef * IR_t +
           IT_t_coef * IT_t +
           IR_t_squared_coef * IR_t_squared +
           IT_t_squared_coef * IT_t_squared +
           IR_t_IT_t_coef * IR_t_IT_t)

df_lbl <- df_with_coef %>% 
  group_split(district_no, accumulation_period) %>% 
  map_dfr(~ .x %>% select(district_no, accumulation_period) %>% distinct())

df_corr <-df_with_coef %>% 
  group_split(district_no, accumulation_period) %>% 
  map_dfr( ~ .x %>% select(Y_t, prediction) %>% cor() %>% data.frame() %>% 
             select(prediction) %>% slice(1) %>% rename(coef_=prediction))

df_lbl$corrcoef_ <- df_corr$coef_
df_corr <- df_lbl

df_corr$corrcoef_ %>% min() # No negative coefficient

best_corr_per_district <- df_corr %>%
  group_split(district_no) %>%
  map(~ .x %>% arrange(desc(corrcoef_)) %>% slice(1)) %>%
  bind_rows()

# Display the best correlations
print(best_corr_per_district)

# Save the best correlations to a CSV file
write.csv(best_corr_per_district, 'best_corr_per_district_diff.csv', row.names = FALSE)

df_chosen_acc <- df_corr %>% 
  group_split(district_no) %>% 
  map(~ .x %>% arrange(desc(corrcoef_)) %>% slice(1)) %>% 
  do.call(what=bind_rows) %>% 
  select(-corrcoef_)

df_chosen_acc <- df_chosen_acc %>% 
  left_join(df, by=c('district_no','accumulation_period'))

df_chosen_acc_with_pred <- df_chosen_acc %>% 
  tibble() %>%
  inner_join(models_stations_wider, by=c("district_no", "accumulation_period")) %>% 
  mutate(
    IR_t_squared = IR_t^2,
    IT_t_squared = IT_t^2,
    IR_t_IT_t = IR_t * IT_t,
    prediction = Intercept_coef +
      IR_t_coef * IR_t +
      IT_t_coef * IT_t +
      IR_t_squared_coef * IR_t_squared +
      IT_t_squared_coef * IT_t_squared +
      IR_t_IT_t_coef * IR_t_IT_t
  ) %>% 
  select(district_no:IT_t, prediction)

# Save the final dataframe with predictions
write.csv(df_chosen_acc_with_pred, 'district_wi_diff.csv', row.names=FALSE)
